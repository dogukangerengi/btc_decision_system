# =============================================================================
# VERÄ° Ã‡EKME MODÃœLÃœ (DATA FETCHER) - v2.0
# =============================================================================
# AmaÃ§: CCXT kÃ¼tÃ¼phanesi ile kripto borsalarÄ±ndan OHLCV verisi Ã§ekmek
# GÃ¼ncelleme: TÃ¼m timeframe'ler + maksimum veri Ã§ekme desteÄŸi
# 
# Ä°statistiksel Not: Daha fazla veri = daha gÃ¼venilir backtest sonuÃ§larÄ±
# Ancak Ã§ok eski veri piyasa rejim deÄŸiÅŸikliklerini iÃ§erebilir (non-stationarity)
# =============================================================================

import ccxt                                    # Kripto borsa API'leri iÃ§in unified interface
import pandas as pd                            # Zaman serisi veri yapÄ±sÄ±
import numpy as np                             # SayÄ±sal hesaplamalar
from datetime import datetime, timedelta, timezone  # Zaman iÅŸlemleri (timezone-aware)
from typing import Optional, List, Dict, Tuple      # Tip belirteÃ§leri (type hints)
import time                                    # Rate limiting iÃ§in bekleme
from pathlib import Path                       # Dosya yolu iÅŸlemleri


class DataFetcher:
    """
    Kripto borsalarÄ±ndan OHLCV verisi Ã§eken sÄ±nÄ±f.
    
    GÃ¼ncelleme v2.0:
    - TÃ¼m timeframe'ler eklendi (5m, 30m, 2h dahil)
    - Maksimum veri Ã§ekme (Binance limitine kadar)
    - Veri kaydetme/yÃ¼kleme fonksiyonlarÄ±
    - GeliÅŸmiÅŸ hata yÃ¶netimi
    
    Ä°statistiksel Ã–nem:
    - Backtest iÃ§in yeterli veri: minimum 1000 bar Ã¶nerilir
    - Walk-forward validation iÃ§in: minimum 30 gÃ¼nlÃ¼k out-of-sample
    - Rejim deÄŸiÅŸikliÄŸi riski: 6 aydan eski veriye dikkat
    """
    
    # -------------------------------------------------------------------------
    # TÃœM DESTEKLENEN ZAMAN DÄ°LÄ°MLERÄ°
    # -------------------------------------------------------------------------
    # Binance'in desteklediÄŸi tÃ¼m timeframe'ler
    # Dakika cinsinden karÅŸÄ±lÄ±klarÄ± (volatilite Ã¶lÃ§ekleme iÃ§in gerekli)
    
    TIMEFRAME_MINUTES: Dict[str, int] = {
        "1m": 1,          # 1 dakika   - Scalping, Ã§ok gÃ¼rÃ¼ltÃ¼lÃ¼
        "3m": 3,          # 3 dakika   - KÄ±sa vadeli scalping
        "5m": 5,          # 5 dakika   - KÄ±sa vadeli trading â­ YENÄ°
        "15m": 15,        # 15 dakika  - Day trading standardÄ±
        "30m": 30,        # 30 dakika  - Orta-kÄ±sa vade â­ YENÄ°
        "1h": 60,         # 1 saat     - Day trading / Swing
        "2h": 120,        # 2 saat     - Orta vade â­ YENÄ°
        "4h": 240,        # 4 saat     - Swing trading iÃ§in ideal
        "6h": 360,        # 6 saat     - Orta-uzun vade
        "8h": 480,        # 8 saat     - Pozisyon trading
        "12h": 720,       # 12 saat    - Pozisyon trading
        "1d": 1440,       # 1 gÃ¼n      - Pozisyon / HODLing
        "3d": 4320,       # 3 gÃ¼n      - Uzun vade
        "1w": 10080,      # 1 hafta    - Uzun vade trend
    }
    
    # -------------------------------------------------------------------------
    # BÄ°NANCE VERÄ° LÄ°MÄ°TLERÄ°
    # -------------------------------------------------------------------------
    # Binance API limitleri ve Ã¶nerilen Ã§ekme stratejisi
    
    BINANCE_LIMITS = {
        'max_candles_per_request': 1000,      # Tek istekte maksimum mum
        'rate_limit_per_minute': 1200,        # Dakikada maksimum istek
        'recommended_delay': 0.1,             # Ä°stekler arasÄ± bekleme (saniye)
    }
    
    # -------------------------------------------------------------------------
    # HER TIMEFRAME Ä°Ã‡Ä°N Ã–NERÄ°LEN VERÄ° MÄ°KTARI (Day Trading Optimize)
    # -------------------------------------------------------------------------
    # Day trading iÃ§in daha fazla veri = daha gÃ¼venilir backtest
    # KÄ±sa timeframe'lerde gÃ¼rÃ¼ltÃ¼ fazla, bu yÃ¼zden daha Ã§ok sample gerekli
    
    RECOMMENDED_BARS: Dict[str, int] = {
        "1m": 10000,      # ~7 gÃ¼n (scalping analizi iÃ§in)
        "3m": 7000,       # ~14 gÃ¼n
        "5m": 5000,       # ~17 gÃ¼n â­ Day trading kÄ±sa vade
        "15m": 4000,      # ~42 gÃ¼n (~6 hafta) â­ Day trading ana TF
        "30m": 3000,      # ~62 gÃ¼n (~2 ay) â­ Trend konfirmasyonu
        "1h": 2000,       # ~83 gÃ¼n (~3 ay) â­ Ä°ntraday trend
        "2h": 1500,       # ~125 gÃ¼n (~4 ay) â­ Swing noktalarÄ±
        "4h": 1000,       # ~166 gÃ¼n (~5.5 ay) â­ BÃ¼yÃ¼k resim
        "6h": 750,        # ~187 gÃ¼n
        "8h": 600,        # ~200 gÃ¼n
        "12h": 500,       # ~250 gÃ¼n
        "1d": 365,        # 1 yÄ±l
        "3d": 200,        # ~600 gÃ¼n
        "1w": 104,        # 2 yÄ±l
    }
    
    # -------------------------------------------------------------------------
    # AKTÄ°F TÄ°MEFRAME'LER (Day Trading iÃ§in optimize edilmiÅŸ)
    # -------------------------------------------------------------------------
    # Not: Binance 10m desteklemiyor, en yakÄ±n alternatifler kullanÄ±ldÄ±
    # Multi-resolution analiz: KÄ±sa (5m-15m), Orta (30m-1h), Uzun (2h-4h)
    
    ACTIVE_TIMEFRAMES: List[str] = [
        "5m",             # KÄ±sa vade - Entry/Exit timing, scalping
        "15m",            # KÄ±sa vade - Day trading ana timeframe
        "30m",            # Orta vade - Trend konfirmasyonu
        "1h",             # Orta vade - Ä°ntraday trend yapÄ±sÄ±
        "2h",             # Uzun vade - Swing noktalarÄ±
        "4h",             # Uzun vade - BÃ¼yÃ¼k resim, major S/R
    ]
    
    def __init__(
        self,
        exchange_id: str = "binance",         # VarsayÄ±lan borsa
        symbol: str = "BTC/USDT",             # VarsayÄ±lan iÅŸlem Ã§ifti
        sandbox: bool = False                  # Test modu
    ):
        """
        DataFetcher sÄ±nÄ±fÄ±nÄ± baÅŸlatÄ±r.
        
        Parametreler:
        ------------
        exchange_id : str
            CCXT borsa ID'si (binance, bybit, okx, vb.)
            
        symbol : str
            Ä°ÅŸlem Ã§ifti (BTC/USDT, ETH/USDT, vb.)
            
        sandbox : bool
            True ise test ortamÄ± kullanÄ±lÄ±r
        """
        
        # Borsa nesnesini oluÅŸtur
        self.exchange = getattr(ccxt, exchange_id)({
            'sandbox': sandbox,
            'enableRateLimit': True,          # Otomatik rate limiting
            'options': {
                'defaultType': 'spot',
            }
        })
        
        self.symbol = symbol
        self.exchange_id = exchange_id
        
        # Market bilgilerini yÃ¼kle
        self._load_markets()
    
    def _load_markets(self) -> None:
        """Borsa market bilgilerini yÃ¼kler."""
        try:
            self.exchange.load_markets()
            print(f"âœ“ {self.exchange_id.upper()} borsasÄ± baÄŸlantÄ±sÄ± baÅŸarÄ±lÄ±")
            print(f"  Toplam {len(self.exchange.markets)} market mevcut")
        except ccxt.NetworkError as e:
            raise ConnectionError(f"AÄŸ hatasÄ±: {e}")
        except ccxt.ExchangeError as e:
            raise ValueError(f"Borsa hatasÄ±: {e}")
    
    def fetch_ohlcv(
        self,
        timeframe: str = "1h",
        limit: int = 1000,                    # Binance max: 1000
        since: Optional[int] = None
    ) -> pd.DataFrame:
        """
        Belirtilen timeframe iÃ§in OHLCV verisi Ã§eker.
        
        Parametreler:
        ------------
        timeframe : str
            Zaman dilimi (TIMEFRAME_MINUTES'daki deÄŸerlerden biri)
            
        limit : int
            Ã‡ekilecek maksimum bar sayÄ±sÄ± (Binance max: 1000)
            
        since : int, optional
            BaÅŸlangÄ±Ã§ zamanÄ± (Unix timestamp, milisaniye)
        
        DÃ¶ndÃ¼rÃ¼r:
        --------
        pd.DataFrame
            Kolonlar: timestamp(index), open, high, low, close, volume
        """
        
        # Timeframe geÃ§erliliÄŸini kontrol et
        if timeframe not in self.TIMEFRAME_MINUTES:
            valid_tfs = list(self.TIMEFRAME_MINUTES.keys())
            raise ValueError(f"GeÃ§ersiz timeframe: {timeframe}. GeÃ§erli: {valid_tfs}")
        
        # Sembol kontrolÃ¼
        if self.symbol not in self.exchange.markets:
            raise ValueError(f"{self.symbol} bu borsada mevcut deÄŸil")
        
        # Limit kontrolÃ¼ (Binance max 1000)
        limit = min(limit, self.BINANCE_LIMITS['max_candles_per_request'])
        
        try:
            ohlcv_raw = self.exchange.fetch_ohlcv(
                symbol=self.symbol,
                timeframe=timeframe,
                limit=limit,
                since=since
            )
            
            if not ohlcv_raw:
                raise ValueError(f"{self.symbol} iÃ§in veri bulunamadÄ±")
            
            # DataFrame oluÅŸtur
            df = pd.DataFrame(
                ohlcv_raw,
                columns=['timestamp', 'open', 'high', 'low', 'close', 'volume']
            )
            
            # Timestamp'i timezone-aware datetime'a Ã§evir
            df['timestamp'] = pd.to_datetime(df['timestamp'], unit='ms', utc=True)
            df.set_index('timestamp', inplace=True)
            df.index.name = None
            
            # Veri tiplerini optimize et
            df = df.astype({
                'open': 'float64',
                'high': 'float64',
                'low': 'float64',
                'close': 'float64',
                'volume': 'float64'
            })
            
            return df
            
        except ccxt.NetworkError as e:
            raise ConnectionError(f"AÄŸ hatasÄ± (veri Ã§ekme): {e}")
        except ccxt.ExchangeError as e:
            raise ValueError(f"Borsa hatasÄ± (veri Ã§ekme): {e}")
    
    def fetch_max_ohlcv(
        self,
        timeframe: str = "1h",
        max_bars: Optional[int] = None,       # None = Ã¶nerilen miktar
        progress: bool = True                  # Ä°lerleme gÃ¶ster
    ) -> pd.DataFrame:
        """
        Belirtilen timeframe iÃ§in MAKSÄ°MUM veri Ã§eker.
        
        Binance'in 1000 bar limitini GERÄ°YE DOÄRU pagination ile aÅŸar.
        Rate limiting otomatik uygulanÄ±r.
        
        Parametreler:
        ------------
        timeframe : str
            Zaman dilimi
            
        max_bars : int, optional
            Ã‡ekilecek maksimum bar sayÄ±sÄ±
            None ise RECOMMENDED_BARS deÄŸeri kullanÄ±lÄ±r
            
        progress : bool
            True ise ilerleme durumu yazdÄ±rÄ±lÄ±r
        
        DÃ¶ndÃ¼rÃ¼r:
        --------
        pd.DataFrame
            BirleÅŸtirilmiÅŸ OHLCV DataFrame
        
        Ä°statistiksel Not:
        -----------------
        Daha fazla veri:
        + Daha gÃ¼venilir backtest (larger sample size)
        + Daha iyi out-of-sample validation
        - Piyasa rejim deÄŸiÅŸikliÄŸi riski (non-stationarity)
        - Ä°ÅŸlem maliyeti yapÄ±sÄ± deÄŸiÅŸmiÅŸ olabilir
        
        Ã–neri: 3-6 ay veri optimal trade-off saÄŸlar
        """
        
        # Hedef bar sayÄ±sÄ±nÄ± belirle
        if max_bars is None:
            max_bars = self.RECOMMENDED_BARS.get(timeframe, 1000)
        
        # Timeframe dakika deÄŸeri
        tf_minutes = self.TIMEFRAME_MINUTES[timeframe]
        
        # Tahmini gÃ¼n sayÄ±sÄ±
        estimated_days = (max_bars * tf_minutes) / (60 * 24)
        
        if progress:
            print(f"\nğŸ“Š {self.symbol} | {timeframe} | Hedef: {max_bars} bar (~{estimated_days:.1f} gÃ¼n)")
        
        # =====================================================================
        # GERÄ°YE DOÄRU PAGÄ°NATION STRATEJÄ°SÄ°
        # =====================================================================
        # Binance'de 'since' = "bu tarihten SONRA" demek
        # Bu yÃ¼zden geÃ§miÅŸ tarihten baÅŸlayÄ±p ileri doÄŸru Ã§ekiyoruz
        # =====================================================================
        
        # BaÅŸlangÄ±Ã§ tarihini hesapla (ÅŸu an - tahmini sÃ¼re - buffer)
        # Buffer: Hafta sonlarÄ±/tatiller iÃ§in ekstra %20
        buffer_factor = 1.2
        start_time = datetime.now(timezone.utc) - timedelta(minutes=int(max_bars * tf_minutes * buffer_factor))
        since_ms = int(start_time.timestamp() * 1000)
        
        all_data: List[pd.DataFrame] = []
        total_fetched = 0
        chunk_size = self.BINANCE_LIMITS['max_candles_per_request']
        current_since = since_ms
        
        while total_fetched < max_bars:
            # Kalan bar sayÄ±sÄ±
            remaining = max_bars - total_fetched
            fetch_limit = min(chunk_size, remaining)
            
            try:
                # Chunk Ã§ek (since parametresi ile geÃ§miÅŸten baÅŸla)
                df_chunk = self.fetch_ohlcv(
                    timeframe=timeframe,
                    limit=fetch_limit,
                    since=current_since
                )
                
                if df_chunk.empty:
                    if progress:
                        print(f"   âš  Veri sonu (toplam: {total_fetched})")
                    break
                
                all_data.append(df_chunk)
                total_fetched += len(df_chunk)
                
                # Sonraki chunk iÃ§in: SON bar'Ä±n timestamp'i + 1ms
                # Ä°LERÄ° DOÄRU gidiyoruz (geÃ§miÅŸten ÅŸu ana)
                last_ts = df_chunk.index[-1]
                current_since = int(last_ts.timestamp() * 1000) + 1
                
                if progress:
                    print(f"   â†’ {total_fetched}/{max_bars} bar Ã§ekildi ({100*total_fetched/max_bars:.1f}%)")
                
                # EÄŸer beklenen miktardan az geldiyse, daha fazla veri yok
                if len(df_chunk) < fetch_limit:
                    if progress:
                        print(f"   âœ“ Veri sonu ulaÅŸÄ±ldÄ±")
                    break
                
                # Åu ana ulaÅŸtÄ±ysak dur
                if last_ts >= datetime.now(timezone.utc) - timedelta(minutes=tf_minutes):
                    if progress:
                        print(f"   âœ“ GÃ¼ncel veriye ulaÅŸÄ±ldÄ±")
                    break
                
                # Rate limiting
                time.sleep(self.BINANCE_LIMITS['recommended_delay'])
                
            except Exception as e:
                if progress:
                    print(f"   âš  Hata (devam ediliyor): {e}")
                # Hata durumunda kÄ±sa bekleme ve devam
                time.sleep(0.5)
                break
        
        if not all_data:
            raise ValueError(f"{timeframe} iÃ§in veri Ã§ekilemedi")
        
        # TÃ¼m chunk'larÄ± birleÅŸtir
        df_combined = pd.concat(all_data)
        
        # Duplicate'leri kaldÄ±r
        df_combined = df_combined[~df_combined.index.duplicated(keep='last')]
        
        # Kronolojik sÄ±rala
        df_combined = df_combined.sort_index()
        
        # Ä°stenen bar sayÄ±sÄ±na kÄ±rp (fazla Ã§ekmiÅŸ olabiliriz)
        if len(df_combined) > max_bars:
            df_combined = df_combined.tail(max_bars)
        
        if progress:
            actual_days = (df_combined.index[-1] - df_combined.index[0]).days
            print(f"   âœ“ Toplam: {len(df_combined)} bar | {actual_days} gÃ¼n | "
                  f"{df_combined.index[0].strftime('%Y-%m-%d')} â†’ {df_combined.index[-1].strftime('%Y-%m-%d')}")
        
        return df_combined
    
    def fetch_all_timeframes(
        self,
        timeframes: Optional[List[str]] = None,   # None = ACTIVE_TIMEFRAMES
        max_bars_override: Optional[int] = None,  # Her timeframe iÃ§in aynÄ± bar sayÄ±sÄ±
        save_to_disk: bool = False,               # CSV olarak kaydet
        data_dir: str = "data"                    # KayÄ±t klasÃ¶rÃ¼
    ) -> Dict[str, pd.DataFrame]:
        """
        TÃœM aktif timeframe'ler iÃ§in veri Ã§eker.
        
        Parametreler:
        ------------
        timeframes : List[str], optional
            Ã‡ekilecek timeframe listesi
            None ise ACTIVE_TIMEFRAMES kullanÄ±lÄ±r
            
        max_bars_override : int, optional
            Her timeframe iÃ§in sabit bar sayÄ±sÄ±
            None ise RECOMMENDED_BARS kullanÄ±lÄ±r
            
        save_to_disk : bool
            True ise veriler CSV olarak kaydedilir
            
        data_dir : str
            KayÄ±t klasÃ¶rÃ¼ yolu
        
        DÃ¶ndÃ¼rÃ¼r:
        --------
        Dict[str, pd.DataFrame]
            Anahtar: timeframe, DeÄŸer: OHLCV DataFrame
        
        KullanÄ±m:
        --------
        >>> fetcher = DataFetcher()
        >>> all_data = fetcher.fetch_all_timeframes()
        >>> print(all_data.keys())  # dict_keys(['5m', '15m', '30m', '1h', '2h', '4h', '1d'])
        """
        
        # Timeframe listesi
        if timeframes is None:
            timeframes = self.ACTIVE_TIMEFRAMES
        
        print("=" * 60)
        print(f"ğŸ“¥ TÃœM TIMEFRAME'LER Ä°Ã‡Ä°N VERÄ° Ã‡EKÄ°LÄ°YOR")
        print(f"   Symbol: {self.symbol}")
        print(f"   Timeframe'ler: {timeframes}")
        print("=" * 60)
        
        data_dict: Dict[str, pd.DataFrame] = {}
        
        for tf in timeframes:
            try:
                # Bar sayÄ±sÄ±nÄ± belirle
                bars = max_bars_override if max_bars_override else self.RECOMMENDED_BARS.get(tf, 1000)
                
                # Veri Ã§ek
                df = self.fetch_max_ohlcv(
                    timeframe=tf,
                    max_bars=bars,
                    progress=True
                )
                
                data_dict[tf] = df
                
                # Disk'e kaydet (opsiyonel)
                if save_to_disk:
                    self._save_to_csv(df, tf, data_dir)
                
            except Exception as e:
                print(f"\n   âœ— {tf} iÃ§in hata: {e}")
                continue
            
            # Timeframe'ler arasÄ± bekleme
            time.sleep(0.5)
        
        # Ã–zet tablo
        self._print_summary(data_dict)
        
        return data_dict
    
    def _save_to_csv(
        self,
        df: pd.DataFrame,
        timeframe: str,
        data_dir: str
    ) -> None:
        """Veriyi CSV dosyasÄ±na kaydeder."""
        
        # KlasÃ¶r oluÅŸtur
        Path(data_dir).mkdir(parents=True, exist_ok=True)
        
        # Dosya adÄ±: BTC_USDT_1h_20240125.csv
        symbol_clean = self.symbol.replace("/", "_")
        date_str = datetime.now(timezone.utc).strftime("%Y%m%d")
        filename = f"{symbol_clean}_{timeframe}_{date_str}.csv"
        filepath = Path(data_dir) / filename
        
        df.to_csv(filepath)
        print(f"   ğŸ’¾ Kaydedildi: {filepath}")
    
    def _print_summary(self, data_dict: Dict[str, pd.DataFrame]) -> None:
        """Ã‡ekilen verilerin Ã¶zetini yazdÄ±rÄ±r."""
        
        print("\n" + "=" * 60)
        print("ğŸ“Š VERÄ° Ã‡EKÄ°M Ã–ZETÄ°")
        print("=" * 60)
        print(f"{'Timeframe':<10} {'Bars':<10} {'BaÅŸlangÄ±Ã§':<12} {'BitiÅŸ':<12} {'GÃ¼n':<6}")
        print("-" * 60)
        
        for tf, df in data_dict.items():
            start = df.index[0].strftime('%Y-%m-%d')
            end = df.index[-1].strftime('%Y-%m-%d')
            days = (df.index[-1] - df.index[0]).days
            print(f"{tf:<10} {len(df):<10} {start:<12} {end:<12} {days:<6}")
        
        print("=" * 60)
    
    def fetch_multi_timeframe(
        self,
        timeframes: List[str] = ["15m", "1h", "4h"],
        limit: int = 500,
        delay: float = 0.5
    ) -> Dict[str, pd.DataFrame]:
        """
        Birden fazla timeframe iÃ§in OHLCV verisi Ã§eker (basit versiyon).
        Geriye uyumluluk iÃ§in korunmuÅŸtur.
        """
        
        data_dict: Dict[str, pd.DataFrame] = {}
        
        for tf in timeframes:
            print(f"  â†’ {tf} verisi Ã§ekiliyor...", end=" ")
            
            try:
                df = self.fetch_ohlcv(timeframe=tf, limit=limit)
                data_dict[tf] = df
                print(f"âœ“ ({len(df)} bar)")
            except Exception as e:
                print(f"âœ— Hata: {e}")
                continue
            
            time.sleep(delay)
        
        return data_dict
    
    def fetch_historical(
        self,
        timeframe: str = "1h",
        days: int = 30,
        chunk_size: int = 1000
    ) -> pd.DataFrame:
        """
        Belirtilen gÃ¼n sayÄ±sÄ± kadar geÃ§miÅŸ veriyi Ã§eker.
        Geriye uyumluluk iÃ§in korunmuÅŸtur.
        """
        
        tf_minutes = self.TIMEFRAME_MINUTES[timeframe]
        total_bars_needed = int((days * 24 * 60) / tf_minutes)
        
        return self.fetch_max_ohlcv(
            timeframe=timeframe,
            max_bars=total_bars_needed,
            progress=True
        )
    
    def validate_data(self, df: pd.DataFrame) -> Dict[str, any]:
        """
        Ã‡ekilen verinin kalitesini doÄŸrular.
        
        Kontroller:
        1. Missing values
        2. OHLC tutarlÄ±lÄ±ÄŸÄ± (High >= Open/Close, Low <= Open/Close)
        3. Volume anomalileri
        4. Zaman sÃ¼rekliliÄŸi
        
        DÃ¶ndÃ¼rÃ¼r:
        --------
        Dict[str, any]
            Veri kalite metrikleri
        """
        
        validation_results = {}
        
        # 1. Toplam satÄ±r sayÄ±sÄ±
        validation_results['total_rows'] = len(df)
        
        # 2. Missing value kontrolÃ¼
        missing_counts = df.isnull().sum().to_dict()
        validation_results['missing_values'] = missing_counts
        validation_results['has_missing'] = any(v > 0 for v in missing_counts.values())
        
        # 3. OHLC tutarlÄ±lÄ±k kontrolÃ¼
        high_valid = (df['high'] >= df['open']) & (df['high'] >= df['close'])
        low_valid = (df['low'] <= df['open']) & (df['low'] <= df['close'])
        ohlc_invalid_count = (~high_valid | ~low_valid).sum()
        validation_results['ohlc_invalid_rows'] = int(ohlc_invalid_count)
        
        # 4. Volume kontrolÃ¼
        zero_volume = (df['volume'] == 0).sum()
        negative_volume = (df['volume'] < 0).sum()
        validation_results['zero_volume_rows'] = int(zero_volume)
        validation_results['negative_volume_rows'] = int(negative_volume)
        
        # 5. Zaman aralÄ±ÄŸÄ±
        validation_results['start_date'] = df.index.min().strftime('%Y-%m-%d %H:%M')
        validation_results['end_date'] = df.index.max().strftime('%Y-%m-%d %H:%M')
        
        # 6. Temel istatistikler
        validation_results['price_range'] = {
            'min': float(df['low'].min()),
            'max': float(df['high'].max()),
            'last': float(df['close'].iloc[-1])
        }
        
        # 7. Volume istatistikleri
        validation_results['volume_stats'] = {
            'mean': float(df['volume'].mean()),
            'median': float(df['volume'].median()),
            'std': float(df['volume'].std())
        }
        
        # 8. Gap analizi (eksik bar tespiti)
        if len(df) > 1:
            time_diffs = df.index.to_series().diff().dropna()
            expected_diff = time_diffs.mode()[0] if len(time_diffs.mode()) > 0 else time_diffs.median()
            gaps = (time_diffs > expected_diff * 1.5).sum()
            validation_results['detected_gaps'] = int(gaps)
        else:
            validation_results['detected_gaps'] = 0
        
        # Genel geÃ§erlilik
        validation_results['is_valid'] = (
            not validation_results['has_missing'] and
            ohlc_invalid_count == 0 and
            negative_volume == 0
        )
        
        return validation_results
    
    def get_latest_price(self) -> Dict[str, float]:
        """GÃ¼ncel fiyat bilgisini Ã§eker (ticker)."""
        
        try:
            ticker = self.exchange.fetch_ticker(self.symbol)
            
            return {
                'last': ticker['last'],
                'bid': ticker['bid'],
                'ask': ticker['ask'],
                'volume_24h': ticker['quoteVolume'],
                'change_24h': ticker['percentage'],
                'high_24h': ticker['high'],
                'low_24h': ticker['low'],
                'timestamp': datetime.now(timezone.utc).strftime('%Y-%m-%d %H:%M:%S UTC')
            }
            
        except Exception as e:
            raise ValueError(f"Ticker Ã§ekme hatasÄ±: {e}")
    
    def get_available_timeframes(self) -> List[str]:
        """KullanÄ±labilir tÃ¼m timeframe'leri dÃ¶ndÃ¼rÃ¼r."""
        return list(self.TIMEFRAME_MINUTES.keys())
    
    def get_active_timeframes(self) -> List[str]:
        """Aktif (analiz iÃ§in kullanÄ±lan) timeframe'leri dÃ¶ndÃ¼rÃ¼r."""
        return self.ACTIVE_TIMEFRAMES.copy()


# =============================================================================
# MODÃœL TEST KODU
# =============================================================================

if __name__ == "__main__":
    
    print("=" * 70)
    print("DATA FETCHER v2.0 TEST")
    print("=" * 70)
    
    # DataFetcher Ã¶rneÄŸi oluÅŸtur
    fetcher = DataFetcher(
        exchange_id="binance",
        symbol="BTC/USDT"
    )
    
    # 1. KullanÄ±labilir timeframe'leri gÃ¶ster
    print("\n[1] KullanÄ±labilir Timeframe'ler:")
    print(f"   TÃ¼mÃ¼: {fetcher.get_available_timeframes()}")
    print(f"   Aktif: {fetcher.get_active_timeframes()}")
    
    # 2. GÃ¼ncel fiyat
    print("\n[2] GÃ¼ncel Fiyat:")
    price = fetcher.get_latest_price()
    print(f"   BTC/USDT: ${price['last']:,.2f}")
    print(f"   24h DeÄŸiÅŸim: {price['change_24h']:.2f}%")
    
    # 3. Tek timeframe maksimum veri Ã§ekme testi
    print("\n[3] Tek Timeframe Maksimum Veri (1h):")
    df_1h = fetcher.fetch_max_ohlcv(timeframe="1h", max_bars=500)
    print(f"   Son 5 bar:\n{df_1h.tail()}")
    
    # 4. Veri doÄŸrulama
    print("\n[4] Veri DoÄŸrulama:")
    validation = fetcher.validate_data(df_1h)
    print(f"   Toplam: {validation['total_rows']} bar")
    print(f"   GeÃ§erli: {validation['is_valid']}")
    print(f"   Gap sayÄ±sÄ±: {validation['detected_gaps']}")
    
    # 5. TÃ¼m aktif timeframe'ler iÃ§in veri Ã§ekme (kÃ¼Ã§Ã¼k miktar - test iÃ§in)
    print("\n[5] Day Trading Timeframe'leri (test - 100 bar):")
    all_data = fetcher.fetch_all_timeframes(
        timeframes=["5m", "15m", "30m", "1h", "2h", "4h"],  # Day trading TF'ler
        max_bars_override=100,            # KÃ¼Ã§Ã¼k miktar (test iÃ§in)
        save_to_disk=False
    )
    
    print("\n" + "=" * 70)
    print("TÃœM TESTLER TAMAMLANDI")
    print("=" * 70)
